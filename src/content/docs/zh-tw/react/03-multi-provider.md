---
title: 'ReAct æ¨¡å¼ï¼šå¤šæä¾›è€…å¯¦ä½œ'
description: 'ä½¿ç”¨ LangChain æ¡†æ¶æˆ–æ‰‹å‹•æŠ½è±¡æ¨¡å¼ï¼Œå»ºæ§‹å¯è·¨ Claudeã€GPTã€Gemini æˆ–æœ¬åœ°æ¨¡å‹ç„¡ç¸«å·¥ä½œçš„ ReAct ä»£ç†ã€‚'
---

## æ¦‚è¦½

æœ¬æŒ‡å—å±•ç¤ºå¦‚ä½•å»ºæ§‹å¯åœ¨å¤šå€‹ LLM æä¾›è€…ï¼ˆClaudeã€GPTã€Geminiã€æœ¬åœ°æ¨¡å‹ï¼‰ä¹‹é–“ç„¡ç¸«å·¥ä½œçš„ ReAct ä»£ç†ï¼Œè€Œç„¡éœ€é‡å¯«ä»£ç†é‚è¼¯ã€‚

**å…©ç¨®æ–¹æ³•ï¼š**

1. **LangChainï¼ˆæ¨è–¦ï¼‰** - å…·æœ‰å…§å»ºæŠ½è±¡çš„ç”Ÿç”¢å°±ç·’æ¡†æ¶
2. **æ‰‹å‹•æŠ½è±¡ï¼ˆæ•™å­¸ï¼‰** - è‡ªå·±å»ºæ§‹ä»¥ç†è§£å…§éƒ¨é‹ä½œ

## ç‚ºä»€éº¼æä¾›è€…æŠ½è±¡å¾ˆé‡è¦

**æ²’æœ‰æŠ½è±¡ï¼š**

```python
# é–å®šåˆ° Claude
import anthropic
client = anthropic.Anthropic()
response = client.messages.create(model="claude-sonnet-4-5", ...)

# æƒ³åˆ‡æ›åˆ° GPTï¼Ÿé‡å¯«æ‰€æœ‰æ±è¥¿ï¼
import openai
client = openai.OpenAI()
response = client.chat.completions.create(model="gpt-4", ...)
```

**æœ‰æŠ½è±¡ï¼š**

```python
# ä¸€è¡Œåˆ‡æ›æä¾›è€…
# llm = ChatAnthropic(model="claude-sonnet-4-5")
llm = ChatOpenAI(model="gpt-4-turbo")  # åªæ”¹é€™è¡Œï¼

# ä»£ç†ç¨‹å¼ç¢¼ä¿æŒä¸è®Š
response = llm.invoke("Your prompt")
```

**å¥½è™•ï¼š**

- **ä¾›æ‡‰å•†ç¨ç«‹** - ä¸é–å®šåˆ°å–®ä¸€æä¾›è€…
- **æˆæœ¬å„ªåŒ–** - ç°¡å–®ä»»å‹™ä½¿ç”¨æ›´ä¾¿å®œçš„æ¨¡å‹
- **å¯é æ€§** - å¦‚æœä¸€å€‹æä¾›è€…å¤±æ•—è‡ªå‹•å‚™æ´
- **A/B æ¸¬è©¦** - è¼•é¬†æ¯”è¼ƒæ¨¡å‹æ•ˆèƒ½

## æ–¹æ³• 1ï¼šLangChainï¼ˆæ¨è–¦ï¼‰

> **æœ€æ–°**: LangChain 1.2.8 (2026) æ­é… [LangGraph](https://langchain-ai.github.io/langgraph/) ç”¨æ–¼ç”Ÿç”¢ä»£ç†

### å®‰è£

```bash
pip install langchain==1.2.8 langchain-anthropic langchain-openai langchain-google-genai langchain-community
```

### æ­¥é©Ÿ 1ï¼šç†è§£ LangChain çš„çµ±ä¸€ä»‹é¢

LangChain ç‚ºæ‰€æœ‰æä¾›è€…æä¾›æ¨™æº–ä»‹é¢ï¼š

```python
from langchain_anthropic import ChatAnthropic
from langchain_openai import ChatOpenAI
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_community.llms import Ollama

# å…¨éƒ¨éƒ½æœ‰ç›¸åŒçš„ä»‹é¢
llm_claude = ChatAnthropic(model="claude-sonnet-4-5", temperature=0)
llm_gpt = ChatOpenAI(model="gpt-4-turbo", temperature=0)
llm_gemini = ChatGoogleGenerativeAI(model="gemini-1.5-pro", temperature=0)
llm_local = Ollama(model="mistral")

# ç›¸åŒçš„æ–¹æ³•é©ç”¨æ–¼æ‰€æœ‰æä¾›è€…
response_claude = llm_claude.invoke("Hello!")
response_gpt = llm_gpt.invoke("Hello!")
response_gemini = llm_gemini.invoke("Hello!")
```

**é—œéµè¦‹è§£**ï¼šå¯«ä¸€æ¬¡ï¼Œåˆ°è™•åŸ·è¡Œã€‚

### æ­¥é©Ÿ 2ï¼šä¸€æ¬¡å®šç¾©å·¥å…·

ä½¿ç”¨ LangChain çš„ `@tool` è£é£¾å™¨å®šç¾©é©ç”¨æ–¼æ‰€æœ‰æä¾›è€…çš„å·¥å…·ï¼š

```python
from langchain_core.tools import tool
import os

@tool
def read_file(path: str) -> str:
    """å¾ç£ç¢Ÿè®€å–æª”æ¡ˆã€‚

    Args:
        path: è¦è®€å–çš„æª”æ¡ˆè·¯å¾‘
    """
    try:
        with open(path, 'r') as f:
            content = f.read()
            return f"Success: {content[:1000]}..."
    except Exception as e:
        return f"Error: {str(e)}"

@tool
def write_file(path: str, content: str) -> str:
    """å°‡å…§å®¹å¯«å…¥æª”æ¡ˆã€‚

    Args:
        path: è¦å¯«å…¥çš„æª”æ¡ˆè·¯å¾‘
        content: è¦å¯«å…¥çš„å…§å®¹
    """
    try:
        os.makedirs(os.path.dirname(path) or ".", exist_ok=True)
        with open(path, 'w') as f:
            f.write(content)
        return f"Success: Wrote to {path}"
    except Exception as e:
        return f"Error: {str(e)}"

@tool
def list_files(folder: str) -> str:
    """åˆ—å‡ºç›®éŒ„ä¸­çš„æª”æ¡ˆã€‚

    Args:
        folder: è³‡æ–™å¤¾è·¯å¾‘
    """
    try:
        files = os.listdir(folder)
        docs = [f for f in files if f.endswith(('.pdf', '.txt', '.md'))]
        return f"Found {len(docs)} documents: {', '.join(docs)}"
    except Exception as e:
        return f"Error: {str(e)}"

# é€™äº›å·¥å…·é©ç”¨æ–¼ä»»ä½•æä¾›è€…ï¼
tools = [read_file, write_file, list_files]
```

**å·¥å…·ç¶å®š** - å°‡å·¥å…·é™„åŠ åˆ°ä»»ä½• LLMï¼š

```python
claude_with_tools = llm_claude.bind_tools(tools)
gpt_with_tools = llm_gpt.bind_tools(tools)
gemini_with_tools = llm_gemini.bind_tools(tools)

# å…¨éƒ¨ä»¥ç›¸åŒæ–¹å¼é‹ä½œï¼
```

### æ­¥é©Ÿ 3ï¼šä½¿ç”¨ create_react_agentï¼ˆLangChain ç¶“å…¸ï¼‰

ä½¿ç”¨ `AgentExecutor` çš„å‚³çµ±æ–¹æ³•ï¼š

```python
from langchain.agents import create_react_agent, AgentExecutor
from langchain_core.prompts import PromptTemplate

# å»ºç«‹ ReAct æç¤ºæ¨¡æ¿
react_prompt = PromptTemplate.from_template("""
You are a legal review assistant. Answer the following question as best you can.

You have access to the following tools:

{tools}

Use the following format:

Question: the input question you must answer
Thought: you should always think about what to do
Action: the action to take, should be one of [{tool_names}]
Action Input: the input to the action
Observation: the result of the action
... (this Thought/Action/Action Input/Observation can repeat N times)
Thought: I now know the final answer
Final Answer: the final answer to the original input question

Begin!

Question: {input}
Thought: {agent_scratchpad}
""")

# é¸æ“‡ä½ çš„æä¾›è€…ï¼ˆåªæ”¹é€™è¡Œï¼ï¼‰
llm = ChatAnthropic(model="claude-sonnet-4-5", temperature=0)
# llm = ChatOpenAI(model="gpt-4-turbo", temperature=0)
# llm = ChatGoogleGenerativeAI(model="gemini-1.5-pro", temperature=0)

# å»ºç«‹ä»£ç†
agent = create_react_agent(
    llm=llm,
    tools=tools,
    prompt=react_prompt
)

# å»ºç«‹åŸ·è¡Œå™¨
agent_executor = AgentExecutor(
    agent=agent,
    tools=tools,
    verbose=True,
    handle_parsing_errors=True,
    max_iterations=20
)

# åŸ·è¡Œï¼
result = agent_executor.invoke({
    "input": "Review all legal documents in /project/legal_docs and create LEGAL_NOTICES.md"
})

print(result["output"])
```

### æ­¥é©Ÿ 4ï¼šè‡ªè¨‚ ReAct è¿´åœˆï¼ˆæ›´å¤šæ§åˆ¶ï¼‰

ç‚ºäº†ç´°ç²’åº¦æ§åˆ¶ï¼Œå»ºæ§‹ä½ è‡ªå·±çš„è¿´åœˆï¼š

```python
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage, ToolMessage

class CustomReActAgent:
    """ä½¿ç”¨ LangChain å…ƒä»¶çš„è‡ªè¨‚ ReAct ä»£ç†"""

    def __init__(self, llm, tools: list):
        self.llm = llm
        self.tools = tools
        self.tool_map = {tool.name: tool for tool in tools}
        self.llm_with_tools = llm.bind_tools(tools)

    def run(self, user_request: str, max_iterations: int = 20) -> str:
        """åŸ·è¡Œ ReAct è¿´åœˆ"""

        messages = [
            SystemMessage(content="""You are a legal review assistant.
Work step-by-step:
1. Scan documents in folder
2. Review each document
3. Create LEGAL_NOTICES.md with findings
4. Create REVIEW_SUMMARY.md with summary

When completely done, respond with your final summary (don't call more tools).
"""),
            HumanMessage(content=user_request)
        ]

        for iteration in range(1, max_iterations + 1):
            print(f"\n{'='*60}")
            print(f"Iteration {iteration}/{max_iterations}")
            print(f"{'='*60}")

            # å‘¼å« LLM
            response = self.llm_with_tools.invoke(messages)

            # æª¢æŸ¥æ˜¯å¦å®Œæˆï¼ˆæ²’æœ‰æ›´å¤šå·¥å…·å‘¼å«ï¼‰
            if not response.tool_calls:
                print("\nâœ… COMPLETED")
                return response.content

            # å°‡ AI å›æ‡‰åŠ å…¥æ­·å²
            messages.append(response)

            # åŸ·è¡Œå·¥å…·å‘¼å«
            for tool_call in response.tool_calls:
                tool_name = tool_call["name"]
                tool_args = tool_call["args"]

                print(f"\nâš¡ Action: {tool_name}")
                print(f"   Args: {tool_args}")

                # åŸ·è¡Œ
                if tool_name in self.tool_map:
                    result = self.tool_map[tool_name].invoke(tool_args)
                else:
                    result = f"Error: Unknown tool {tool_name}"

                print(f"ğŸ‘€ Observation: {result[:200]}...")

                # åŠ å…¥å·¥å…·çµæœ
                messages.append(ToolMessage(
                    content=str(result),
                    tool_call_id=tool_call["id"]
                ))

        return "Failed to complete within iteration limit"

# ä½¿ç”¨ - è¼•é¬†åˆ‡æ›æä¾›è€…ï¼
llm = ChatAnthropic(model="claude-sonnet-4-5", temperature=0)
# llm = ChatOpenAI(model="gpt-4-turbo", temperature=0)
# llm = ChatGoogleGenerativeAI(model="gemini-1.5-pro", temperature=0)

agent = CustomReActAgent(llm, tools)
result = agent.run("Review all legal documents in /project/legal_docs")
```

### æ­¥é©Ÿ 5ï¼šLangGraphï¼ˆç”Ÿç”¢æ¨è–¦ï¼‰

> **2026 æ–°åŠŸèƒ½**: [LangGraph](https://langchain-ai.github.io/langgraph/) ç¾åœ¨æ˜¯ç”Ÿç”¢ä»£ç†çš„æ¨è–¦æ¡†æ¶

```python
# ä½¿ç”¨ LangGraph çš„ç¾ä»£æ–¹æ³•
from langgraph.prebuilt import create_react_agent as create_agent_langgraph

# é¸æ“‡æä¾›è€…
llm = ChatAnthropic(model="claude-sonnet-4-5")

# ä½¿ç”¨ LangGraph å»ºç«‹ä»£ç†ï¼ˆæ›´å¥½çš„é è¨­å€¼ï¼Œæ›´å¼·å¥ï¼‰
agent = create_agent_langgraph(
    model=llm,
    tools=tools,
    # å…§å»ºåŠŸèƒ½ï¼š
    # - è‡ªå‹•é‡è©¦é‚è¼¯
    # - éŒ¯èª¤è™•ç†ä¸­ä»‹è»Ÿé«”
    # - ç‹€æ…‹ç®¡ç†
    # - ä¸²æµæ”¯æ´
)

# åŸ·è¡Œä»£ç†
result = agent.invoke({
    "messages": [HumanMessage(content="Review legal docs in /project/legal_docs")]
})

print(result["messages"][-1].content)
```

**LangGraph å„ªå‹¢ï¼š**

- âœ… æ›´å¼·å¥çš„éŒ¯èª¤è™•ç†
- âœ… æ›´å¥½çš„æŒ‡æ•¸é€€é¿é‡è©¦é‚è¼¯
- âœ… åŸç”Ÿä¸²æµæ”¯æ´
- âœ… æ¨¡çµ„åŒ–ä»£ç†è¨­è¨ˆ
- âœ… ç›¸å®¹æ–¼ [MCPï¼ˆæ¨¡å‹ä¸Šä¸‹æ–‡å”å®šï¼‰](https://modelcontextprotocol.io/)

## æ–¹æ³• 2ï¼šæ‰‹å‹•æŠ½è±¡ï¼ˆæ•™å­¸ï¼‰

å¾é ­é–‹å§‹ç†è§£å¦‚ä½•å»ºæ§‹æŠ½è±¡ï¼Œæœ‰åŠ©æ–¼ä½ ç†è§£ LangChain å…§éƒ¨åšäº†ä»€éº¼ã€‚

### æ­¥é©Ÿ 1ï¼šæ¨™æº–è³‡æ–™æ¨¡å‹

å®šç¾©èˆ‡æä¾›è€…ç„¡é—œçš„è³‡æ–™çµæ§‹ï¼š

```python
from dataclasses import dataclass
from typing import List, Dict, Any, Optional, Literal
from enum import Enum

class MessageRole(Enum):
    USER = "user"
    ASSISTANT = "assistant"
    SYSTEM = "system"

@dataclass
class Message:
    """æ¨™æº–åŒ–è¨Šæ¯æ ¼å¼"""
    role: MessageRole
    content: str

@dataclass
class Tool:
    """æ¨™æº–åŒ–å·¥å…·å®šç¾©"""
    name: str
    description: str
    parameters: Dict[str, Any]  # JSON Schema

@dataclass
class ToolCall:
    """æ¨™æº–åŒ–å·¥å…·å‘¼å«"""
    id: str
    name: str
    arguments: Dict[str, Any]

@dataclass
class LLMResponse:
    """æ¨™æº–åŒ– LLM å›æ‡‰"""
    content: str
    tool_calls: List[ToolCall]
    finish_reason: Literal["stop", "tool_calls", "length"]
    metadata: Dict[str, Any]  # ä½¿ç”¨çµ±è¨ˆ
```

### æ­¥é©Ÿ 2ï¼šæŠ½è±¡æä¾›è€…ä»‹é¢

```python
from abc import ABC, abstractmethod

class LLMProvider(ABC):
    """æ‰€æœ‰æä¾›è€…çš„æŠ½è±¡åŸºç¤"""

    @abstractmethod
    def complete(self, messages: List[Message], tools: List[Tool]) -> LLMResponse:
        """å‚³é€è«‹æ±‚ä¸¦å–å¾—æ¨™æº–åŒ–å›æ‡‰"""
        pass

    @abstractmethod
    def supports_native_tools(self) -> bool:
        """æ­¤æä¾›è€…æ˜¯å¦æ”¯æ´åŸç”Ÿå·¥å…·å‘¼å«ï¼Ÿ"""
        pass
```

è©³ç´°çš„æ‰‹å‹•å¯¦ä½œï¼ˆåŒ…å« Claudeã€OpenAIã€Gemini å’Œæœ¬åœ°æ¨¡å‹çš„é©é…å™¨ï¼‰è«‹åƒè¦‹å®Œæ•´æ–‡ä»¶æˆ–å¾ä¸Šè¿°é€æ­¥ç¯„ä¾‹æ”¹ç·¨ã€‚

## æä¾›è€…æ¯”è¼ƒçŸ©é™£

| æä¾›è€…                | åŸç”Ÿå·¥å…·    | é€Ÿåº¦   | æˆæœ¬ | æœ€é©åˆ           |
| --------------------- | ----------- | ------ | ---- | ---------------- |
| **Claude Sonnet 4.5** | âœ… æ˜¯       | å¿«     | $$   | é€šç”¨ï¼Œé«˜å“è³ª     |
| **Claude Opus 4.6**   | âœ… æ˜¯       | æ…¢     | $$$$ | è¤‡é›œæ¨ç†ï¼Œè¦åŠƒ   |
| **Claude Haiku 4.5**  | âœ… æ˜¯       | éå¸¸å¿« | $    | ç°¡å–®ä»»å‹™ï¼Œé©—è­‰   |
| **GPT-4 Turbo**       | âœ… æ˜¯       | å¿«     | $$$  | é€šç”¨             |
| **GPT-3.5 Turbo**     | âœ… æ˜¯       | éå¸¸å¿« | $    | ç°¡å–®ä»»å‹™         |
| **Gemini 1.5 Pro**    | âœ… æ˜¯       | å¿«     | $$   | å¤šæ¨¡æ…‹ï¼Œé•·ä¸Šä¸‹æ–‡ |
| **Gemini 1.5 Flash**  | âœ… æ˜¯       | éå¸¸å¿« | $    | å¿«é€Ÿæ¨ç†         |
| **Mistralï¼ˆæœ¬åœ°ï¼‰**   | âš ï¸ é€é XML | å–æ±ºæ–¼ | å…è²» | éš±ç§ï¼Œé›¢ç·š       |
| **Llama 3ï¼ˆæœ¬åœ°ï¼‰**   | âš ï¸ é€é XML | å–æ±ºæ–¼ | å…è²» | éš±ç§ï¼Œé›¢ç·š       |

## ç”Ÿç”¢å»ºè­°

### ä½•æ™‚ä½¿ç”¨ä»€éº¼

**ä½¿ç”¨ LangChain/LangGraph ç•¶ï¼š**

- âœ… å»ºæ§‹ç”Ÿç”¢æ‡‰ç”¨ç¨‹å¼
- âœ… éœ€è¦å¼·å¥çš„éŒ¯èª¤è™•ç†
- âœ… æƒ³è¼•é¬†åˆ‡æ›æä¾›è€…
- âœ… å¾ç”Ÿæ…‹ç³»çµ±å—ç›Šï¼ˆå·¥å…·ã€è¨˜æ†¶é«”ã€éˆï¼‰
- âœ… éœ€è¦å¿«é€Ÿé–‹ç™¼

**å»ºæ§‹æ‰‹å‹•æŠ½è±¡ç•¶ï¼š**

- ğŸ“ å­¸ç¿’ä»£ç†å¦‚ä½•åœ¨å…§éƒ¨é‹ä½œ
- ğŸ”§ éœ€è¦éå¸¸å…·é«”çš„æ§åˆ¶
- âš¡ æ•ˆèƒ½è‡³é—œé‡è¦ï¼ˆæœ€å°é–‹éŠ·ï¼‰
- ğŸ”’ å®‰å…¨æ€§éœ€è¦é¿å…ä¾è³´

### è·¨æä¾›è€…æ¸¬è©¦

```python
import pytest

def test_agent_all_providers():
    """é©—è­‰ä»£ç†é©ç”¨æ–¼æ‰€æœ‰æä¾›è€…"""

    providers = {
        "claude": ChatAnthropic(model="claude-sonnet-4-5"),
        "gpt": ChatOpenAI(model="gpt-4-turbo"),
        "gemini": ChatGoogleGenerativeAI(model="gemini-1.5-pro"),
    }

    for name, llm in providers.items():
        print(f"\nTesting with {name}...")

        agent = CustomReActAgent(llm, tools)
        result = agent.run("List files in /test")

        assert result is not None, f"{name} failed"
        print(f"âœ… {name} passed")
```

### æˆæœ¬å„ªåŒ–ç­–ç•¥

```python
def get_llm_for_task(complexity: str):
    """æ ¹æ“šä»»å‹™è¤‡é›œåº¦é¸æ“‡æ¨¡å‹"""

    if complexity == "low":
        # ä½¿ç”¨æœ€ä¾¿å®œçš„é¸é …
        return ChatAnthropic(model="claude-haiku-4-5")
        # or ChatOpenAI(model="gpt-3.5-turbo")

    elif complexity == "medium":
        # å¹³è¡¡æˆæœ¬å’Œå“è³ª
        return ChatAnthropic(model="claude-sonnet-4-5")
        # or ChatOpenAI(model="gpt-4-turbo")

    else:  # high
        # ä½¿ç”¨æœ€æœ‰èƒ½åŠ›çš„
        return ChatAnthropic(model="claude-opus-4-6")
        # or ChatOpenAI(model="gpt-4")

# ä½¿ç”¨
llm = get_llm_for_task("medium")
agent = CustomReActAgent(llm, tools)
```

## é—œéµè¦é»

1. **LangChain å…è²»æä¾›æŠ½è±¡** - é™¤éä½ æœ‰ç‰¹å®šåŸå› ï¼Œå¦å‰‡ä½¿ç”¨å®ƒ
2. **æä¾›è€…åˆ‡æ›å¾ˆç°¡å–®** - æ”¹è®Šä¸€è¡Œç¨‹å¼ç¢¼
3. **ä½¿ç”¨å¤šå€‹æä¾›è€…æ¸¬è©¦** - è¡Œç‚ºå¯èƒ½æœ‰ç´°å¾®å·®ç•°
4. **æœ¬åœ°æ¨¡å‹éœ€è¦ XML å‚™æ´** - å¤§å¤šæ•¸ä¸æ”¯æ´åŸç”Ÿå·¥å…·å‘¼å«
5. **LangGraph æ˜¯æœªä¾†** - ç”¨æ–¼æ–°çš„ç”Ÿç”¢ä»£ç†

## ç›¸é—œè³‡æº

- [LangChain æ–‡ä»¶](https://docs.langchain.com/oss/python/langchain/agents)
- [LangGraph æŒ‡å—](https://langchain-ai.github.io/langgraph/)
- [LangChain v1.1.0 ç™¼å¸ƒèªªæ˜](https://blog.langchain.com/langchain-langgraph-1dot0/)
- [æ¨¡å‹ä¸Šä¸‹æ–‡å”å®šï¼ˆMCPï¼‰](https://modelcontextprotocol.io/)

## ä¸‹ä¸€æ­¥

- **å¾ç°¡å–®é–‹å§‹**ï¼šä½¿ç”¨ LangChain çš„ `create_react_agent` é€²è¡Œå¿«é€ŸåŸå‹é–‹ç™¼
- **é€²å…¥ç”Ÿç”¢**ï¼šé·ç§»åˆ° LangGraph çš„ `create_agent` ä»¥ç²å¾—å¼·å¥çš„æ‡‰ç”¨ç¨‹å¼
- **å­¸ç¿’å…§éƒ¨åŸç†**ï¼šå»ºæ§‹æ‰‹å‹•æŠ½è±¡ä»¥ç†è§£ LangChain çš„ä½œç”¨
- **é€²éšæ¨¡å¼**ï¼šæ¢ç´¢[è¨ˆåŠƒ-åŸ·è¡Œ-é©—è­‰](/ai-agent-study/zh-tw/plan-execute-verify/01-overview/)ä»¥ç²å¾—ç”Ÿç”¢ç³»çµ±
